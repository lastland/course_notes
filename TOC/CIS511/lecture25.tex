%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%
% This template is based on the template for Prof. Sinclair's CS 270.

\documentclass[twoside]{article}
\usepackage{graphics}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{IEEEtrantools}
\usepackage{amsmath,amssymb,trimclip,adjustbox}

\mathchardef\mhyphen="2D % Define a "math hyphen"

\usetikzlibrary{chains,fit,shapes}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\chno}[4]{
   \pagestyle{headings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CIS 511: Theory of Computation
                        \hfill Apr 20, 2017} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Professor #3 \hfill #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}
   {\bf NB}: {\it These notes are from CIS511 at Penn. The course followed Michael Sipser's \textit{Introduction to the Theory of Computation (3ed)} text.}
   \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\chno{25}{Practical Approaches to NP}{Sampath Kannan}{Zach Schutzman}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\section*{Optimization Problems}

Optimization problems usually minimize or maximize things.  We would like ways to solve $NP$-Complete optimization problems, like minimum Vertex Cover, maximum clique, etc.

\definition{An algorithm $A$ achieves an \textbf{approximation ratio} of $C$ if for all inputs $x$, $\frac{A(x)}{OPT(x)}\leq C$, where $A(x)$ is $A$'s result and $OPT(x)$ is the optimal result.}


\subsection*{Vertex Cover}
Let's think about Vertex Cover.  Given a graph $G$, we want to find the smallest set of vertices such that every edge of $G$ is incident to a vertex in the cover.  

\definition{A \textbf{maximal matching} is a set of edges in a graph which form a matching such that no other edge can be added and have it still remain a matching.}

A maximal matching can be found efficiently by a greedy algorithm.  Let $M$ be a maximal matching and $V(M)$ be the set of vertices in the matching.  We have $|V(M)|=2|M|$, so $OPT(G)\geq |M|$.  We claim $V(M)$ is a Vertex Cover.  To see this, suppose that it is not.  Then some edge $(u,v)$ is not covered by $V(M)$.  But then we could add $(u,v)$ to $M$, contradicting the assumption that $M$ is a maximal matching.

Therefore, a maximal matching is a $2$-approximation for finding a Vertex Cover.

Note that reductions do not necessarily preserve approximation factors.  Think of Vertex Cover and Independent Set.  Simply taking the complement of a $2$-approximate Vertex Cover could result in a size zero Independent Set if every vertex was added to the cover.  In fact, Independent Set is strongly non-approximable (as is clique), and finding a good approximation algorithm would prove $P=NP$

\subsection*{Set Cover}

Now, let's think of Set Cover.  Here, we are given a universe $S$ of $n$ elements and a collection of $m$ subsets $S_1,S_2,\dots, S_m$.  We want to find a minimum number of subsets such that their union is equal to $S$.  Vertex cover is a special case of Set Cover, where the universe is the set of edges and the subsets are the sets of edges incident to each vertex.

A greedy algorithm to approximate Set Cover is to iteratively pick the $S_i$ with the largest number of uncovered elements until we cover everything.  Suppose the greedy algorithm selects $k$ subsets $S_{i_1},S_{i_2}$.  We know that $S_{i_1}$ covers at least $\frac{n}{k}$ elements, as either it or a strictly smaller subset must be included in the optimal solution, as our greedy algorithm picks the largest subset at the first step.  Consider $S_{i_2}$.  For the same reason, we have that $S_{i_2}$ covers at least $\frac{n(1-\frac{1}{k})}{k}$ elements, and so on.  We can upper-bound the number of uncovered elements after $t$ rounds by $n(1-\frac{1}{k})^t$.  We want to find the $t$ such that this becomes smaller than $1$.  By taking some logarithms and doing algebra, we get $l\approx k\\ln(n)$ as the number of sets the greedy algorithm will choose.  This is therefore a $\ln(n)$-approximation to Set Cover.  We can also prove that this is tight.  If Set Cover has a $(\ln(n)-\epsilon)$-approximation algorithm, then $P=NP$.

\subsection*{Subset-Sum}

The optimization version of the Subset-Sum problem, which asks to find a subset of a universe $a_1,a_2,\dots,a_n$ whose sum is maximum subject to it being less than or equal to a target $T$.  To solve this exactly, we can just check all $2^n$ subsets, and pick the one that sums to the largest value less than or equal to $T$.  We can do this in exponential time with a dynamic programming approach by keeping an array $L$ such that $L_i$ is the list of sums we can get with a subset of the first $i$ elements, and we construct $L_{i+1}=L_i \oplus \{0,a_{i+1}\}$.  This runs in time $nT$, but running time of $T$ is not polynomial.

We can find an arbitrarily good approximation to this problem.  That is, for any $\epsilon>0$, we have $\frac{OPT(I)}{A(I)}=1+\epsilon$.  Our approximation is similar to the dynamic programming.  At each step, we eliminate from $L$ any value that is above $T$ or within a factor of $(1+\delta)$ of some other value.  That is, for each element $z$, eliminate all remaining elements between $z$ and $1+\delta$.  This trimming process means that we have elements that are no closer together than $z_1$, $z_1(1+\delta)$, $z_1(1+\delta)^2$, and so on, where $z_1$ is the first element of the list.

Since $z_1$ is at least $1$, there are at most $\log_{1+\delta}(T)$ elements in any $L_i$.  This is approximately $\frac{\log(T)}{\delta}$, so we get a relation that the length of the list increases as $\delta$ gets closer to zero.  We also know that the length of $L_{i+1}$ is twice that of $L_i$, but since we are trimming at each step, the list never gets too big.  $\log(T)$ is polynomial in $T$, so the total running time is $\frac{n\log(T)}{\delta}$.

How good of an approximation is this?  By pruning values, we get no further than $(1+\delta)^n$, so if we set $\delta=\frac{\epsilon}{n}$, we get an approximation factor which looks like $(1+\frac{\epsilon}{n})^n$, which is close to $e^\epsilon$, and for small $\epsilon$, this is roughly $1+\epsilon$.

\end{document}

