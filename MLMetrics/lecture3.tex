%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%
% This template is based on the template for Prof. Sinclair's CS 270.

\documentclass[twoside]{article}
\usepackage{graphics}
\usepackage{amsfonts}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\chno}[4]{
   \pagestyle{headings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CIS 700/4: Machine Learning and Econometrics
                        \hfill January 24, 2017} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Professor #3 \hfill #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}
   {\bf NB}: {\it These notes are from CIS700 at Penn.}
   \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\chno{3}{Rankings from Pairwise Comparisons}{Shivani Agarwal}{Zach Schutzman}


% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.

\section*{Rankings}

Last time: we talked about permutation data and some extension to partially-ranked data.  Today, we'll talk about rankings from pairwise comparisons.

\textbf{Example:} We have chess matches, which are pairwise comparisons with some noise.  We have a budget to allow for 3 more games.  Which games should be played to gain maximal information?

These things show up a lot, in terms of performance, preference, and outcomes.  There are a lot of different approaches for dealing with them, from a wide range of disciplines.

Consider a set of $n$ items, and we note $i\succ j$ if $i$ is preferred to $j$, pairwise.

What might we want?
\begin{enumerate}
	\item[] A learning algorithm for a pairwise probability distribution.
	\item[] Aggregation for a consensus ranking
	\item[] Voting rule to choose a favorite
\end{enumerate}

\textbf{Pairwise comparison estimates} are the fraction of times that $i$ beats $j$ over the number of time the two are compared.  $\hat{P}_{ij} = \frac{W_{ij}}{N_{ij}}$.  Assign $0=\frac{0}{0}$.

\textbf{Copeland Pairwise Voting Rule} assigns score $C(i) = \sum\limits_{i\neq j} \boldmath{1}(\hat{P}_{ij} > \frac{1}{2})$

%\textbf{Minimizing pairwise disagreement on data} for permutation $\sigma$ is $er(\sigma) = \sum\limits_{i\neq j} p>1/2 and sig(i) > sig(j) or p (sig(i) > sig(j))

This looks like the Kemeny ranking and is also NP-Hard in general

Other rankings include spectral ranking, least squares, statistical learning methods, etc.

\textbf{Spectral ranking} looks kind of like PageRank.  Construct transition matrix $\hat{Q}_{ij} = \frac{\hat{P}_{ij}}{\sum\limits_{k=1}^n\hat{P}_{ki}}$.

This puts higher rank on the elements more likely to beat others.  You can find a stationary distribution of $\hat{Q}$ like a Markov chain, then sorting the outcomes.

\textbf{Least Squares ranking} finds scores $\hat{s}_i$ satisfying $\hat{s} \in \arg\min \sum(s_i - s_j -\ln{\frac{\hat{P}_{ij}}{\hat{P}_{ji}}})$.

Again, sort and output.


\subsection*{Probabilistic Models}


A probabilistic model is a preference matrix $P \in [0,1]^{n\times n}$


\textbf{The Bradley-Terry-Luce Model} is a set of parameters $\boldmath{w}\in\mathbb{R}^n$ where $P_{ij} = \frac{w_i}{w_i + w_j}$.  These parameters can be found by a MLE procedure using the log-likelihood.


\textbf{The Thurstone Model} is a set of parameters $\boldmath{s} \in \mathbb{R}^n$ such that $P_{ij} = \boldmath{\Phi}(s_i - s_j)$, where $\boldmath{\Phi}$ is the CDF of the standard normal distribution.  This implies that $P_{ij} > \frac{1}{2} \iff s_i > s_j$.  This is the method used in the Elo system.

Parameters can be estimated with a least-squares method, where we find $\hat{s} \in \arg\min \sum ((s_i-s_j)-\Phi^{-1}(\hat{P}_{ij}))^2$

\textbf{Score-based Models} are parameters generated by a transformation function such that $P_{ij}$ increases with how strongly $i$ beats $j$. The BTL model is a special class of score-based models.

\textbf{Random Utility Models} use random variables $X_1\dots X_n$, and we set $P_{ij} = \Pr(X_i > X_j)$.  

If we say the $X_i$ are Gumbel random variables, then we get the logistic case of the score-based models.

If we say the $X_i$ are normal random variables, then $P_{ij} = \Phi (\frac{\mu_i - \mu_j}{\sqrt{2}})$


\subsection*{Properties in comparison models}

Does the model belong to a particular family?

Does the model satisfy some conditions:

\textbf{Noisy Permutation Property:} there exists some $\sigma\in S_n$ and a $p<.5$, then $P_{ij}$ is $1-p$ if $\sigma(i) < \sigma(j)$ and $p$ if $\sigma(i) > \sigma(j)$.  That is, if there is a probability $p$ of seeing the wrong outcome, whenever we compare two items, we see the correct outcome with probability $1-p$.

\textbf{Stochastic Transitivity Property}: If $i$ beats $j$ with probability greater than $.5$ and $j$ beats $k$ with probability greater than $.5$, then $i$ beats $k$ with probability greater than $.5$.  Equivalently, there is a complete ordering on the outcomes.

\textbf{Condorcet Winner Property}: the model admits a Condorcet winner, i.e. $\exists i^* \in [n]$ such that $P_{i^*j} > \frac{1}{2} \  \forall i^* \neq j$ 

\textbf{Binary Choice Probability Property}: there is a distribution $p$ on permutations such that $P_{ij} = \boldmath{P}_{\sigma \sim p} (\sigma(i) < \sigma(j)) \ \forall i\neq j$.  That is, the model can be described by choosing comparisons randomly from some distribution.


\section*{Sorting}

Standard sorting requires/assumes outcomes consistent with a total ordering.  We can sort with $n\log(n)$ comparisons if we can choose our comparisons.  We can model this as an algorithm actively choosing a pair and receiving an outcome from an oracle.  A noisy version of this assumes the oracle gives the wrong answer sometimes.

We can think about this as trying to learn something about the underlying permutation, like a generalization of sorting.

\textbf{Dueling bandits} as a form of active learning.  

For $t=1,2\dots$, choose a pair $(i_t,j_t)$, receive feedback $y_t\boldmath{1}(i\succ j)$, where $y_t$ follows a Bernoulli distribution with parameter $p=P_{i_tj_t}$, update internal model.  We might be interested in the arm with the highest payoff, finding a ranking on the arms, etc.







\end{document}







