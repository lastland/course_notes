%
% This is the LaTeX template file for lecture notes for CS294-8,
% Computational Biology for Computer Scientists.  When preparing 
% LaTeX notes for this class, please use this template.
%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi.
%
% This template is based on the template for Prof. Sinclair's CS 270.

\documentclass[twoside]{article}
\usepackage{graphics}
\usepackage{amsfonts}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\chno}[4]{
   \pagestyle{headings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf CIS 700/4: Machine Learning and Econometrics
                        \hfill January 19, 2017} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
       \hbox to 6.28in { {\it Professor #3 \hfill #4} }
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}
   {\bf NB}: {\it These notes are from CIS700 at Penn.}
   \vspace*{4mm}
}

%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\chno{2}{Models and Methods for Ranked Data}{Shivani Agarwal}{Zach Schutzman}
%\footnotetext{These notes are partially based on those of Nigel Mansell.}

% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  
%**** IN GENERAL, BE BRIEF. LONG SCRIBE NOTES, NO MATTER HOW WELL WRITTEN,
%**** ARE NEVER READ BY ANYBODY.


\section{}

For large numbers of items, fully-ranked is usually not practical.

\definition{A \textbf{permutation} on $n$ items is a bijective mapping $\sigma : [n]\rightarrow [n]$.  \\
Also considered an element of the symmetric group on $n$ elements, $S_n$.\\
$\sigma (i) :=$ the position of item $i$.\\
$\sigma^{-1}(j) :=$ the item at position $j$.\\
}

Suppose we have ranked data with full rankings $\sigma_1 \sigma_2 \dots \sigma_M$. \\
We may have a number of questions about this data.
\begin{enumerate}
	\item[] Statistical learning to infer a distribution over the permutations (or some other property)
	\item[] Rank aggregation to find a "consensus" ranking or 'winner'
	\item[] Learn a voting rule to determine winning item(s)
	
\end{enumerate}

\textbf{Example:} Borda Voting Rule: $B(i) := \sum\limits_{m=1}^{M} (n-\sigma_m(i))$.  The Borda Winner is $w\in \arg\max\limits_i B(i)$

\definition{The \textbf{Kendall Tau Distance }between permutations $\sigma$ and $\sigma '$ is:\\
	$d_K(\sigma,\sigma') = \sum\limits_{i<j} \mathbb{1}((\sigma(i) - \sigma(j))(\sigma'(i)-\sigma'(j)) < 0)$\\
	
	i.e. the number of pairs that are flipped between the two rankings
	}

\definition{\textbf{Kemeny Ranking:}\\	
	$\hat{\sigma} \in \arg\min\limits_{\sigma\in S_n} \sum(d_K(\sigma,\sigma'))$

	i.e. find the ranking that minimizes the distance to the data
	
	This requires $O(n!)$ many comparisons, NP-Hard

}


These will show up in web-search applications


\subsection*{}

\definition{A distribution on permutations of $n$ items is an assignment of probability $p(\sigma)$ to each permutation $\sigma\in S_n$.
	
	There are uncountably many such distributions (we need $n! -1$ parameters from $[0,1]$}

We often use families of distributions to make this easier to work with.

\subsubsection*{Mallows Model}


\definition{The Mallows distribution is a probability distribution that looks like $\frac{1}{Z(\theta)} \exp{-\theta d_K (\sigma,\sigma_0)}$, where $\sigma_0\in S_n$ is the modal permutation, $\theta\geq 0$ is the dispersion parameter.  $Z$ is a normalizer.}

This looks kind of Gaussian, as the distribution is a function of the distance from the mean/mode.

How do we estimate parameters? Maximum Likelihood!  Recall the likelihood function $\mathcal{L}(\beta) = \prod p(\sigma_m;\beta)$

Given data $\sigma_1 \dots \sigma_M$, the log-likelihood function is $\ell(\sigma_0,\theta) = -M\ln{Z(\theta)} - \theta \sum\limits_1^M d_K(\sigma_m,\sigma_0)$

But this is equivalent to the Kemeny Rank problem, so it also is NP-Hard.  There is an efficient algorithm if most of the observations are clustered around $\sigma_0$ (i.e. $\theta$ is large).

\subsubsection*{Plackett-Luce Model (PL)}

Parameters $\boldmath{w} = (w_1,\dots,w_n)^T \in \mathbb{R}^+$.

We have $p(\sigma;\boldmath{w}) = \frac{w_{i_1}}{w_{i_1} + \dots w_{i_n}} \frac{w_{i_2}}{w_{i_2} + \dots w_{i_n}} \dots$

We can also find a log-likelihood function, but there is no closed-form expression for the maximizing $\boldmath{\hat{w}}$.  Early algorithms used Newton-Raphson root-finding.  Faster algorithms do minorization-maximization.  Recent work has developed faster spectral methods. Other approaches include method-of-moments.

\subsubsection*{Random Utility Models}

Random variables $X_1,\dots,X_n$ with some joint distribution.

$p(\sigma) = \boldmath{P}(X_{\sigma^{-1}(1)} > X_{\sigma^{-1}(2)} > \dots)$


\textbf{Special Cases:} \\
Gumbel random variables ($X_i \sim e^{-e^{-(x-\mu_i)}}$).  Plackett-Luce is a special case of this.\\
Thurstone Models: $X_i \sim N(\mu_i,1)$




We can define a consensus ranking $\sigma^*$ as the permutation that maximizes the probability $p(\sigma)$ for all $\sigma\in S_n$.

We can define a voting rule as the permutation with the smallest expected rank or the one that has the highest probability of being ranked in the top position.

\subsubsection{Other types of input data}

Top $k$-rankings, partial rankings, pairwise comparisons, marginals (i.e. $\boldmath{P}(\sigma(i) = c)$



\end{document}







